* 浅层神经网络
  * 隐藏层：4个神经元，输出层：一个神经元
  * 注意：每一层计算的时候形状的变化
    * $$Z[1]=W[1]X+b[1]$$ 形状：(4,m) = (4,3) * (3,m) + (4,1)
    * $$A[1]=σ(Z[1])$$ 形状：(4,m)
    * $$Z[2]=W[2]A[1]+b[2]$$ 形状：(1,m) = (1,4) * (4,m)+(1,1)
    * $$A[2]=σ(Z[2])$$,  形状：(1,m)
  * 选用其它激活函数
    * tanh, relu
    * 为什么使用非线性激活函数
      * 线性叠加
  * 分为两个部分进行反向传播
    * 最后一层的梯度计算, dw[2], d[2]
    * 隐层的梯度计算, dw[1], db[1]
* 参数初始化
  * np.random.randn()* 0.01
  * 为什么要随机初始化？
  * 初始化权重大小尽量小 0~1, 0.01?