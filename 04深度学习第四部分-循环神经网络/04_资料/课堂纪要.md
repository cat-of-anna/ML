# 循环神经网络

- 掌握循环神经网络原理
- 手写RNN前向和反向逻辑

### 4.1.1 序列模型

* 定义
  * 自然语言、音频、视频以及其它序列数据的模型

* 类型
  * 语音识别
  * 情感分类
  * 机器翻译

#### 4.1.1.3 为什么在序列模型使用CNN等神经网络效果不好

* 序列关联性
* 序列输入长度不一致，输出长度不一致

### 4.1.2 循环神经网络

* 类型
  * 一对一：固定的输入到输出，**如图像分类**
  * 一对多：固定的输入到序列输出，**如图像的文字描述**
  * 多对一：序列输入到输出，**如情感分析，分类正面负面情绪**
  * 多对多：序列输入到序列的输出，**如机器翻译,称之为编解码网络**
  * 同步多对多：同步序列输入到同步输出，**如文本生成，视频每一帧的分类，也称之为序列生成**

#### 4.1.2.2 基础循环网络介绍

* $$x_{t}$$：网络的输入，每一个时刻的输入
* $$o_{t}$$：网络的输出，每一个时刻的输出
* $$s_{t}$$: 网络的隐层状态输出，穿提到不同时刻当中
* 中间的圆圈表示cell 单元，细胞单元
* U，V，W是参数共享的，所有的cell
  * 每一个cell:有两个输入，前一个cell的状态和当前序列的输入
  * 每一个cell：有两个输出，当前cell的状态和cell的预测输出
  * 输出：收到前面时刻的隐层状态影响

#### 4.1.2.3 序列生成案例

#### 4.1.2.4 词的表示

* one_hot编码表示
* 建立一个所有词的词库，包含（开始和结束标志）
* 每个词都是30000（所有词的个数）长度的向量

#### 4.1.2.4 输出的表示-softmax

* 每一个时刻的输出是，所有词的概率组成的向量（M个词），长度为M
* 使用softmax来计算概率

#### 4.1.2.5 矩阵运算表示

* 假设：m个词，x_t:m长度
  * n是认为指定的一个长度，通常用来指定cell的状态输出大小
  * [u,w] x [\frac{x}{s}sx ] = [n, n+m] x [n +m, 1] = [n, 1]

#### 4.1.2.6 交叉熵损失

* 总误差就是各个时刻词的误差之和。

* #### 4.1.2.7 时序反向传播算法(BPTT)（重要）

  - 目标是计算误差关于**参数U、V和W以及两个偏置bx,by的梯度**
    - 1、**要求：每个时间的梯度都计算出来t=0,t=1,t=2,t=3,t=4，然后加起来的梯度, 为每次W更新的梯度值。**
    - 2、区分最后一个cell和前面的cell的s的梯度值
      - 最后一个：计算最后一个时刻交叉熵损失对于s_t的梯度，记忆交叉熵损失对于s^t,V,by的导数
      - 最后一个前面的cell的ds:
        - 求出当前层损失对于当前隐层状态输出值 s^{t}st 的梯度 + 上一层相对于s^{t}st 的梯度
    - 3、看每一个cell的梯度计算过程
      - 先计算ds^t,然后计算tanh函数梯度
      - 利用链式法则去求出U,W,ba还有x_t,s_t-1的梯度


#### 4.1.2.8 梯度消失与梯度爆炸

### 4.1.3 RNN 总结

* 前向传播
* 反向传播

#### 4.1.4.2 流程

- 前向传播过程

  - 单个cell的前向传播

    - 保存当前ccell的一些输入输出值，反向传播要使用

    - ```
      # 根据公式计算
      # 隐层输出计算
      s_next = np.tanh(np.dot(U, x_t) + np.dot(W, s_prev) + ba)
      
      # 计算cell的输出
      out_pred = softmax(np.dot(V, s_next) + by)
      
      # 记录每一层的值，用于反向传播计算使用
      cache = (s_next, s_prev, x_t, parameters)
      ```

  - 所有cell的前向传播

    - 确定输入的x的形状(m ,1, T)
    - 整个隐层状态值的形状(n, 1, T)
    - 整个输出值的形状：(m, 1, T)

- 反向传播过程

  - 单个cell的反向传播
    - 需要计算哪些梯度值，3个参数和其它的梯度值
  - 多个cell的反向传播
    - **假设知道了所有时刻相对于损失的的ds梯度值**
    - 1、每个cell的s^t，两部分组成
    - 2、不同时刻，对于U,W,ba这些参数需要相加

### 4.1.4 GRU(门控循环单元)

#### 4.1.4.1 什么是GRU

一个重置门（reset gate）和一个更新门（update gate）

- 重置门决定了**如何将新的输入信息与前面的记忆相结合**
- 更新门**定义了前面记忆保存到当前时间步的量**
- 如果将重置门设置为 1，更新门设置为 0，那么将再次获得标准 RNN 模型

#### 4.1.4.2 直观理解

* 本质解决
  * **为了解决短期记忆问题，每个递归单元能够自适应捕捉不同尺度的依赖关系**
  * 解决梯度消失的问题，在隐层输出的地方h_t,h_{t-1}ht,ht−1的关系用加法而不是RNN当中乘法+激活函数

# 4.2 词嵌入与NLP

one_hot编码表示的问题

* 假设有10000个词
  - 每个词的向量长度都为10000，整体大小太大
* 没能表示出词与词之间的关系

### 4.2.2 词嵌入

* 定义：每个词的向量维度低，以及位数是一个实数K

#### 4.2.2.1 特点

* 能够体现出词与词之间的关系
* 能够得到相似词，例如Man - Woman = King - ?

### 4.2.3 Word2Vec案例

- 1、训练模型
  - Word2Vec(LineSentence(inp), size=400, window=5, min_count=5)
- 2、测试模型结果
  - model = gensim.models.Word2Vec.load("*.model")
    - model.most_similar('警察')
    - model.similarity('男人','女人')
    - most_similar(positive=['女人', '丈夫'], negative=['男人'], topn=1)

# 4.3 seq2seq与Attention机制

### 4.3.1 seq2seq

#### 4.3.1.1 定义

**Encoder 中将一个可变长度的信号序列变为固定长度的向量表达**，**Decoder 将这个固定长度的向量变成可变长度的目标的信号序列。**

#### 4.3.1.2 条件语言模型理解

#### 4.3.1.3 应用场景

- 神经机器翻译(NMT)

### 4.3.2 注意力机制

#### 4.3.2.1 长句子问题

#### 4.3.2.2 定义

* encoder到decoder的输出所需要的上下文信息

#### 4.3.2.3 公式

* 1、权重系数与encoder输出进行线性加权运算得到context(t')
  * 计算N个context
* 2、权重系数由来？解码器s(t'-1)为例
  * 解码器s(t'-1)和h(t)(4个时刻)进行运算，经过全连接运算，得到e(t't)4个结果
  * 4个e(t't)经过softmax计算出每一个解码器时刻的4个参数

### 4.3.3 机器翻译案例

#### 4.3.3.1 问题

#### 4.3.3.4 代码分析

- Seq2seq()类实现整个逻辑结构

#### 4.3.3.5 代码编写

* 模型参数确定

  * encoder和decoder时间序列的长度定义（找到最长的，结构要比样本中的长度长）

  * 两个需要手动指定encoder和decoder隐层输出的维度大小（n）

  * ```
    def __init__(self, Tx=30, Ty=10, n_x=32, n_y=64):
    
        self.model_param = {
            "Tx": Tx,  # 定义encoder序列最大长度
            "Ty": Ty,  # decoder序列最大长度
            "n_x": n_x,  # encoder的隐层输出值大小
            "n_y": n_y  # decoder的隐层输出值大小和cell输出值大小
        }
    ```

* 加载日期的特征和目标值数据

  * 特征值日期，目标值日期
    * 1、统计特征值和目标值所有的词的个数，37（包含结尾符号）， 11
    * 2、将原始数据转换成数字形式
    * 3、数字形式进行one_hot编码

* 训练模型逻辑

  * 模型结构的定义

  * **（1）定义好网络的输入输出格式**

    * 整个模型的输入：三个部分x, s0,c0(m, n_y(n=64))

    * 1、步骤

      * 步骤1、定义模型的输入
        * Input(shape=(self.model_param["Tx"], self.model_param["x_vocab_size"]), name="X")
      * 步骤2：使用encoder的双向LSTM结构得输出a
      * 步骤3：循环decoder的Ty次序列输入，获取decoder最后输出
        - 
        - 1: 定义decoder第t'时刻的注意力结构并输出context
          - context = self.computer_one_attention(a, s)(需要实现Attention结构的计算过程)
        - 2: 对"context" 和初始两个状态s0,c0输入到deocder当中,返回两个输出
          - s, _, c = self.decoder(context, initial_state=[s, c])
        - 3: 应用 Dense layere获取deocder的t'时刻的输出 out = self.output_layer(s)
      * 步骤 4: 创建model实例，定义输入输出
        - from keras.models import Model
        - model = Model(inputs=(X, s0, c0), outputs=outputs)

    * 2、模型初始化模型结构定义

      * 编码器

        * Bidirectional(LSTM(self.model_param["n_x"], return_sequences=True, name="bidirectional_1"), merge_mode='concat')

      * 解码器

      * 输出层

        - from keras.layer import Dense

      * Attention

        * 1、定义Attention结构

          * 输入:decoder,s(t'-1),a(t:所有时刻的t)

            ```
                定义Repeat函数
                repeator = RepeatVector(self.model_param["Tx"])
            
                # 2、定义Concat函数
                concatenator = Concatenate(axis=-1)
            
                # 3、定义Dense
                densor1 = Dense(10, activation="tanh", name="Dense1")
            
                densor2 = Dense(1, activation="relu", name='Dense2')
            
                # 4、Activatation
                activator = Activation(softmax,
                                       name='attention_weights')
            
                # 5、Dot相当于npt.dot
                dotor = Dot(axes=1)
            ```

        * 2、根据Attention提供的结构去计算输入到输出的结果
          * decoder,s(t'-1),a(t:所有时刻的t)
          * 1、扩展s_prev的维度到encoder的所有时刻
          * 2、进行s_prev和a进行拼接
            * concat = self.attention["concatenator"]([a, s_prev])
          * 3、进行全连接计算得到e,经过激活函数relu计算出e'
          * 4、e'进过softmax计算，得到系数
          * 5、系数与a进行计算得到context

  * （2）定义好优化器（选择Adam，参数lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001）
    - from keras.optimizers import Adam
    - model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  * （3）模型训练,
    - model.fit(inputs, outputs, epochs=1,batch_size=100)
    - 根据模型的结构去进行定义输入输出的

* 测试

  * 需要加载已有的模型

### 4.3.4 集束搜索（Beam Search）

#### 4.3.4.1 问题引入

* 选出的句子并不是最佳答案，还会有别的选择

#### 4.3.4.2 集束搜索流程

* 定义：每一次筛选时挑top B的结果，b(beam search width)
* 最终得到N组结果，筛选出B个结果，进行筛选

### 4.3.5 BLEU-机器翻译的自动评估方法

* 判断两个句子的相似程度

#### 4.3.5.2 N-gram Precision（多元精度得分）方法

* N？

  * N=1

* 改进

  - 原因：常用词干扰、选词的粒度太小(the)
  - 使用N-gram,多元词组：{“the cat”, “cat is”, “is on”, “on the”, “the mat”}

* ##### 同样还是一个词的时候的改进公式

  * 过滤改进
  * 公式改进
  * 对于the来说：
    * 7，候选翻译：    the    the    the    the    the    the    the
      2，参考翻译：    the    cat    is    on    the    mat    
      1参考翻译：    there    is    a    cat    on    the    mat

* ##### n-gram precision：进行组合

  * n=1:取出所有词进行统计P1
  * n=2:取出所有词组进行组合统计P2
  * n=3:取出所有词组进行组合统计P3
  * N取值越高精度越低
  * 通过集合平均来得到一个通用的公式
  * **exp(1/n∗∑i=1Nlogpn)：精度结果**

* ##### 4、最终BLEU值得计算公式

  * BLEU=BP∗exp(∑n=1Nwn∗logpn)
  * BP:进行长短句的乘法措施
    * 









